{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab36cfd7",
   "metadata": {},
   "source": [
    "### Instalaci칩n de las Librer칤as\n",
    "\n",
    "### Tensorflow \n",
    "\n",
    "TensorFlow es una biblioteca de c칩digo abierto para el aprendizaje autom치tico y las redes neuronales desarrollada por Google. Es ampliamente utilizada para una variedad de tareas de inteligencia artificial, pero es especialmente conocida por su utilidad en el desarrollo de redes neuronales profundas.\n",
    "\n",
    "Dependemos de Tensorflow para el uso de Tensorflow-I/O\n",
    "\n",
    "### Tensorflow-I/O \n",
    "\n",
    "TensorFlow-IO es una extensi칩n de TensorFlow que proporciona un conjunto de funcionalidades de entrada/salida (I/O) para trabajar con diferentes formatos de datos y sistemas de archivos m치s all치 de los que TensorFlow soporta por defecto. \n",
    "\n",
    "Nos permitira utilizar las se침ales que hemos creado para poder transformarlas a un espectrogrma. \n",
    "\n",
    "### Librosa \n",
    "\n",
    "Librosa es una biblioteca de Python para analizar y extraer caracter칤sticas del audio. Proporciona las herramientas necesarias para abrir, procesar y extraer informaci칩n de archivos de audio.\n",
    "\n",
    "Nos permitira extraer los datos y la frecuencia de muestreo que necesitamos de cada uno de los audios que vamos a importar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install tensorflow-io\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb99ab",
   "metadata": {},
   "source": [
    "### Importaci칩n de Audios 游꿨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66723501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path de audios\n",
    "audio_yes_loud = 'Audio/grabados/Yes_fuerte.wav'\n",
    "audio_yes_quiet = 'Audio/grabados/Yes_bajo.wav'\n",
    "audio_no_loud = 'Audio/grabados/No_fuerte.wav'\n",
    "audio_no_quiet = 'Audio/grabados/No_bajo.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca91379",
   "metadata": {},
   "source": [
    "Cargamos los audios y los guardamos en 2 variables \n",
    "\n",
    "1. Un array numpy que contiene la se침al de audio. \n",
    "2. La frecuencia de muestreo `(sr)` de la se침al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2bed723",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yes_loud_array, sr_yes_loud = librosa.load(audio_yes_loud)\n",
    "yes_quiet_array, sr_yes_quiet = librosa.load(audio_yes_quiet)\n",
    "no_loud_array, sr_no_loud = librosa.load(audio_no_loud)\n",
    "no_quiet_array, sr_no_quiet = librosa.load(audio_no_quiet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbed572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimensiones\n",
    "print(len(yes_loud_array))\n",
    "print(yes_loud_array.shape, sr_yes_loud)\n",
    "print(yes_quiet_array.shape, sr_yes_quiet)\n",
    "print(no_loud_array.shape, sr_no_loud)\n",
    "print(no_quiet_array.shape, sr_no_quiet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b6e40e",
   "metadata": {},
   "source": [
    "### Reproduce audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c648de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproduce audio Yes alto\n",
    "ipd.Audio(audio_yes_loud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8fb2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproduce audio Yes bajo\n",
    "ipd.Audio(audio_yes_quiet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eafeed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproduce audio No alto\n",
    "ipd.Audio(audio_no_loud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24def0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproduce audio No bajo\n",
    "ipd.Audio(audio_no_quiet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673153d",
   "metadata": {},
   "source": [
    "### Visualizar se침ales de Audio 游꿨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a096ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the figure\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "# Lista de todos los arrays\n",
    "arrays = [yes_loud_array, yes_quiet_array, no_loud_array, no_quiet_array]\n",
    "\n",
    "# Combina todos los arrays en uno\n",
    "combined_array = np.concatenate(arrays)\n",
    "\n",
    "# Encuentra el valor m치ximo en el array combinado\n",
    "max_val = max(combined_array)\n",
    "\n",
    "ax1.plot(yes_loud_array)\n",
    "ax1.set_title(\"Yes Loud\", {'fontsize':20, 'fontweight':'bold'})\n",
    "ax1.set_ylim(-max_val, max_val)\n",
    "\n",
    "ax2.plot(yes_quiet_array)\n",
    "ax2.set_title(\"Yes Quiet\", {'fontsize':20, 'fontweight':'bold'})\n",
    "ax2.set_ylim(-max_val, max_val)\n",
    "\n",
    "ax3.plot(no_loud_array)\n",
    "ax3.set_title(\"No Loud\", {'fontsize':20, 'fontweight':'bold'})\n",
    "ax3.set_ylim(-max_val, max_val)\n",
    "\n",
    "ax4.plot(no_quiet_array)\n",
    "ax4.set_title(\"No Quiet\", {'fontsize':20, 'fontweight':'bold'})\n",
    "ax4.set_ylim(-max_val, max_val)\n",
    "\n",
    "fig.set_size_inches(18,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22373ad",
   "metadata": {},
   "source": [
    "### Aplicaci칩n de la Transformada de Fourier a las se침ales\n",
    "*Adapted from  [MakersPortal: Audio Processing In Python](https://makersportal.com/blog/2018/9/13/audio-processing-in-python-part-i-sampling-and-the-fast-fourier-transform)*\n",
    "\n",
    "Se introduce la aplicaci칩n de la Transformada de Fourier a las se침ales. La Transformada R치pida de Fourier (FFT, por sus siglas en ingl칠s) se utiliza para convertir una se침al del dominio del tiempo al dominio de la frecuencia, lo que nos permite analizar las frecuencias presentes en una se침al. \n",
    "\n",
    "La funci칩n `np.fft.fft` se utiliza para calcular la FFT, y el resultado es un conjunto de n칰meros complejos. La funci칩n `np.abs` se utiliza para obtener el valor absoluto, lo que elimina la parte imaginaria y nos da la magnitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf393051",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Calcula la transformada r치pida de Fourier de la se침ales y remueve la parte imaginaria \n",
    "ft_audio_yes_loud = np.abs(2*np.fft.fft(yes_loud_array))\n",
    "ft_audio_yes_quiet = np.abs(2*np.fft.fft(yes_quiet_array))\n",
    "ft_audio_no_loud = np.abs(2*np.fft.fft(no_loud_array))\n",
    "ft_audio_no_quiet = np.abs(2*np.fft.fft(no_quiet_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baa5966",
   "metadata": {},
   "source": [
    "### Imprimir la relaci칩n de Amplitud en relaci칩n a la Frecuencia en HZ\n",
    "\n",
    "Se utiliza una escala logar칤tmica para ambos ejes (x & y) para visualizar mejor las caracter칤sticas en un rango amplio de frecuencias y amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffa314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos cada una de las se침ales al plot vac칤o\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "# Le damos un valor a cada uno de los Plots y los escalamos\n",
    "ax1.plot(ft_audio_yes_loud)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_title(\"Yes Loud\", {'fontsize':20, 'fontweight':'bold'})\n",
    "\n",
    "ax2.plot(ft_audio_yes_quiet)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_title(\"Yes Quiet\", {'fontsize':20, 'fontweight':'bold'})\n",
    "\n",
    "ax3.plot(ft_audio_no_loud)\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_yscale('log')\n",
    "ax3.set_title(\"No Loud\", {'fontsize':20, 'fontweight':'bold'})\n",
    "\n",
    "ax4.plot(ft_audio_no_quiet)\n",
    "ax4.set_xscale('log')\n",
    "ax4.set_yscale('log')\n",
    "ax4.set_title(\"No Quiet\", {'fontsize':20, 'fontweight':'bold'})\n",
    "\n",
    "fig.set_size_inches(18,12)\n",
    "fig.text(0.5, 0.06, 'Frequency [Hz]', {'fontsize':20, 'fontweight':'bold'}, ha='center');\n",
    "fig.text(0.08, 0.5, 'Amplitude', {'fontsize':20, 'fontweight':'bold'}, va='center', rotation='vertical');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64aed0b",
   "metadata": {},
   "source": [
    "### Espectrogramas\n",
    "\n",
    "Un espectrograma es una representaci칩n visual de las frecuencias presentes en una se침al a medida que cambia con el tiempo. Es 칰til para analizar c칩mo cambian las frecuencias en una se침al a lo largo del tiempo, y es com칰nmente utilizado en el an치lisis de se침ales de audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f226b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba057b",
   "metadata": {},
   "source": [
    "Se define un tama침o de marco (FRAME_SIZE) para el c치lculo del espectrograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e96dcbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e204c",
   "metadata": {},
   "source": [
    "Se convierten las se침ales de audio en espectrogramas utilizando la funci칩n tfio.audio.spectrogram. La funci칩n toma como argumentos la se침al de audio, el tama침o del marco de la FFT `(nfft)`, la ventana y la distancia entre marcos sucesivos `(stride)`.\n",
    "Nota: El par치metro stride se determina multiplicando la frecuencia de muestreo por **0.008**. Esto representa un desplazamiento de **8 ms** entre marcos sucesivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87c86090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to spectrogram and display\n",
    "# adapted from https://aruno14.medium.com/comparaison-of-audio-representation-in-tensorflow-b6c33a83d77f\n",
    "spectrogram_yes_loud = tfio.audio.spectrogram(yes_loud_array/1.0, nfft=FRAME_SIZE, window=len(yes_loud_array), stride=int(sr_yes_loud * 0.008))\n",
    "spectrogram_yes_quiet = tfio.audio.spectrogram(yes_quiet_array/1.0, nfft=FRAME_SIZE, window=len(yes_quiet_array), stride=int(sr_yes_quiet * 0.008))\n",
    "spectrogram_no_loud = tfio.audio.spectrogram(no_loud_array/1.0, nfft=FRAME_SIZE, window=len(no_loud_array), stride=int(sr_no_loud * 0.008))\n",
    "spectrogram_no_quiet = tfio.audio.spectrogram(no_quiet_array/1.0, nfft=FRAME_SIZE, window=len(no_quiet_array), stride=int(sr_no_quiet * 0.008))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d93b5",
   "metadata": {},
   "source": [
    "Se visualizan los espectrogramas para cada una de las se침ales de audio. Se utiliza la funci칩n imshow para mostrar el espectrograma como una imagen, donde el eje x representa el tiempo, el eje y representa la frecuencia y la intensidad del color representa la amplitud en una frecuencia y tiempo espec칤ficos. Se toma el logaritmo de los espectrogramas para mejorar la visualizaci칩n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f11095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the figure\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "ax1.imshow(tf.math.log(spectrogram_yes_loud).numpy(), aspect='auto')\n",
    "ax1.set_title(\"Yes Loud\", {'fontsize':20, 'fontweight':'bold'})\n",
    "\n",
    "ax2.imshow(tf.math.log(spectrogram_yes_quiet).numpy(), aspect='auto')\n",
    "ax2.set_title(\"Yes Quiet\", {'fontsize':20, 'fontweight':'bold'})\n",
    "\n",
    "ax3.imshow(tf.math.log(spectrogram_no_loud).numpy(), aspect='auto')\n",
    "ax3.set_title(\"No Loud\", {'fontsize':20, 'fontweight':'bold'})\n",
    "\n",
    "ax4.imshow(tf.math.log(spectrogram_no_quiet).numpy(), aspect='auto')\n",
    "ax4.set_title(\"No Quiet\", {'fontsize':20, 'fontweight':'bold'})\n",
    "\n",
    "fig.set_size_inches(18,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b12659",
   "metadata": {},
   "source": [
    "### MFCCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e13e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to MFCC using the Mel Scale\n",
    "# adapted from: https://towardsdatascience.com/getting-to-know-the-mel-spectrogram-31bca3e2d9d0\n",
    "mfcc_yes_loud = librosa.power_to_db(librosa.feature.melspectrogram(\n",
    "    y=np.float32(yes_loud_array), sr=sr_yes_loud, n_fft=2048, hop_length=512, n_mels=128), ref=np.max)\n",
    "\n",
    "mfcc_yes_quiet = librosa.power_to_db(librosa.feature.melspectrogram(\n",
    "    y=np.float32(yes_quiet_array), sr=sr_yes_quiet, n_fft=2048, hop_length=512, n_mels=128), ref=np.max)\n",
    "\n",
    "mfcc_no_loud = librosa.power_to_db(librosa.feature.melspectrogram(\n",
    "    y=np.float32(no_loud_array), sr=sr_no_loud, n_fft=2048, hop_length=512, n_mels=128), ref=np.max)\n",
    "\n",
    "mfcc_no_quiet = librosa.power_to_db(librosa.feature.melspectrogram(\n",
    "    y=np.float32(no_quiet_array), sr=sr_no_quiet, n_fft=2048, hop_length=512, n_mels=128), ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9702659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the figure\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "ax1.imshow(np.swapaxes(mfcc_yes_loud, 0 ,1), interpolation='nearest', cmap=cm.viridis, origin='lower', aspect='auto')\n",
    "ax1.set_title(\"Yes Loud\", {'fontsize':20, 'fontweight':'bold'})\n",
    "ax1.set_ylim(ax1.get_ylim()[::-1])\n",
    "\n",
    "ax2.imshow(np.swapaxes(mfcc_yes_quiet, 0 ,1), interpolation='nearest', cmap=cm.viridis, origin='lower', aspect='auto')\n",
    "ax2.set_title(\"Yes Quiet\", {'fontsize':20, 'fontweight':'bold'})\n",
    "ax2.set_ylim(ax2.get_ylim()[::-1])\n",
    "\n",
    "ax3.imshow(np.swapaxes(mfcc_no_loud, 0 ,1), interpolation='nearest', cmap=cm.viridis, origin='lower', aspect='auto')\n",
    "ax3.set_title(\"No Loud\", {'fontsize':20, 'fontweight':'bold'})\n",
    "ax3.set_ylim(ax3.get_ylim()[::-1])\n",
    "\n",
    "ax4.imshow(np.swapaxes(mfcc_no_quiet, 0 ,1), interpolation='nearest', cmap=cm.viridis, origin='lower', aspect='auto')\n",
    "ax4.set_title(\"No Quiet\", {'fontsize':20, 'fontweight':'bold'})\n",
    "ax4.set_ylim(ax4.get_ylim()[::-1])\n",
    "\n",
    "fig.set_size_inches(18,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6fb14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
